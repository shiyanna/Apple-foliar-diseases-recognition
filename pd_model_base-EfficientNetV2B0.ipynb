{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fbd3f1d-ea05-4e16-ae28-278b8948987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73b2b02e-9cde-403d-b4f4-146c7be42577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class goodsDataset(Dataset):\n",
    "    def __init__(self, df, classes_list, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            df : pandas DataFrame.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = df\n",
    "        self.transform = transform\n",
    "        self.classes_list = classes_list\n",
    "\n",
    "    def encode_label(self, label):\n",
    "        classes_list = list(self.classes_list)\n",
    "        target = torch.zeros(len(classes_list))\n",
    "        for l in label:\n",
    "          idx = classes_list.index(l)\n",
    "          target[idx] = 1\n",
    "        return target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_frame.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        try:\n",
    "            path = self.data_frame.iloc[idx, 0]\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            # label = torch.tensor()\n",
    "            label = self.encode_label(self.data_frame.iloc[idx, 1])\n",
    "\n",
    "            sample = [image, label]\n",
    "            return sample\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"произошла ошибка в goodsDataset при загрузки картинки: {e}\")\n",
    "            return\n",
    "\n",
    "\n",
    "def load_data(df,\n",
    "              transform=None,\n",
    "              batch_size=4,\n",
    "              num_workers=0,\n",
    "              classes_list=None,\n",
    "              shuffle=True):\n",
    "\n",
    "    goods_dataset = goodsDataset(df=df, \n",
    "                                transform=transform,\n",
    "                                classes_list=classes_list)\n",
    "    dataloader = DataLoader(\n",
    "        goods_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs, name_file_save, device='cpu', scheduler=None, save=True):\n",
    "    train_losses, train_accuracies = [], []\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    best_accuracy = 0.0\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_accuracy = 0.0, 0.0\n",
    "        model.train()\n",
    "        for images, labels in tqdm(train_loader, desc='Training'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.shape[0]\n",
    "            train_accuracy += ((logits > 0.5) == labels).sum().item() / labels.numel()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        if save:\n",
    "            mlflow.pytorch.log_model(model, name_file_save)\n",
    "\n",
    "        true_label = np.array([])\n",
    "        predict_label = np.array([])\n",
    "        test_loss, test_accuracy = 0.0, 0.0\n",
    "        model.eval()\n",
    "        for images, labels in tqdm(valid_loader, desc='Validating'):\n",
    "            true_label = np.append(true_label, labels.cpu().numpy())\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                probabilities = torch.sigmoid(logits)\n",
    "                predicted_class = probabilities > 0.5\n",
    "                predict_label = np.append(predict_label, predicted_class.cpu().numpy())\n",
    "\n",
    "            test_loss += loss.item() * images.shape[0]\n",
    "            test_accuracy += ((logits > 0.5) == labels).sum().item() / labels.numel()\n",
    "\n",
    "        test_loss /= len(valid_loader.dataset)\n",
    "        test_accuracy /= len(valid_loader)\n",
    "        valid_losses.append(test_loss)\n",
    "        valid_accuracies.append(test_accuracy)\n",
    "\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        model.load_state_dict(best_weights)\n",
    "        if save:\n",
    "            mlflow.pytorch.log_model(model, name_file_save)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"train_losses\": train_losses[-1],\n",
    "            \"valid_losses\": valid_losses[-1],\n",
    "            \"train_accuracies\": train_accuracies[-1],\n",
    "            \"valid_accuracies\": valid_accuracies[-1],\n",
    "            \"f1_score_macro\": f1_score(true_label, predict_label, average='macro'),\n",
    "            \"f1_score_micro\": f1_score(true_label, predict_label, average='micro'),\n",
    "            \"f1_score_weighted\": f1_score(true_label, predict_label, average='weighted')\n",
    "        }, step=epoch)\n",
    "\n",
    "    return train_losses, train_accuracies, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322c7a3-cf21-480f-a818-a01772cae2f5",
   "metadata": {},
   "source": [
    "# efficientnet_b0, IMAGENET1K_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc8b07d-0890-440c-a175-cfd477c77f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import EfficientNet_B0_Weights, efficientnet_b0\n",
    "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "model = efficientnet_b0(weights=weights)\n",
    "transform = weights.transforms()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae72ac78-e0e8-493b-b686-79c77d1c5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"plantdoc_annotation.csv\", sep=';').drop('Unnamed: 2', axis=1)\n",
    "df['id'] = df['id'].apply(lambda x: 'plantsdoc/' + x)\n",
    "df['classes'] = df['classes'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19fcfee1-2e9f-42f7-8a85-6ef5c5b13738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plantsdoc/ga-2015-05-20-nclb.jpg</td>\n",
       "      <td>[Corn, leaf blight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plantsdoc/corn-disease-update-fig-1-northern-l...</td>\n",
       "      <td>[Corn, leaf blight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plantsdoc/corn-BLS-irregular-lesions.jpg</td>\n",
       "      <td>[Corn, leaf blight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plantsdoc/186116-325x209-Northern-Corn-Leaf-Bl...</td>\n",
       "      <td>[Corn, leaf blight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plantsdoc/nclb-2015-n-mcghee.jpg</td>\n",
       "      <td>[Corn, leaf blight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>plantsdoc/1234080-Early-Blight.jpg</td>\n",
       "      <td>[Tomato, Early blight leaf]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>plantsdoc/rsz0803Figure6.jpg</td>\n",
       "      <td>[Corn, Gray leaf spot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>plantsdoc/show_picture.asp_id=aaaaaaaaaaogcqq&amp;...</td>\n",
       "      <td>[Corn, Gray leaf spot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>plantsdoc/IMG_42231.jpg</td>\n",
       "      <td>[Corn, Gray leaf spot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>plantsdoc/strom5.jpg</td>\n",
       "      <td>[Corn, Gray leaf spot]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2576 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0                      plantsdoc/ga-2015-05-20-nclb.jpg   \n",
       "1     plantsdoc/corn-disease-update-fig-1-northern-l...   \n",
       "2              plantsdoc/corn-BLS-irregular-lesions.jpg   \n",
       "3     plantsdoc/186116-325x209-Northern-Corn-Leaf-Bl...   \n",
       "4                      plantsdoc/nclb-2015-n-mcghee.jpg   \n",
       "...                                                 ...   \n",
       "2571                 plantsdoc/1234080-Early-Blight.jpg   \n",
       "2572                       plantsdoc/rsz0803Figure6.jpg   \n",
       "2573  plantsdoc/show_picture.asp_id=aaaaaaaaaaogcqq&...   \n",
       "2574                            plantsdoc/IMG_42231.jpg   \n",
       "2575                               plantsdoc/strom5.jpg   \n",
       "\n",
       "                          classes  \n",
       "0             [Corn, leaf blight]  \n",
       "1             [Corn, leaf blight]  \n",
       "2             [Corn, leaf blight]  \n",
       "3             [Corn, leaf blight]  \n",
       "4             [Corn, leaf blight]  \n",
       "...                           ...  \n",
       "2571  [Tomato, Early blight leaf]  \n",
       "2572       [Corn, Gray leaf spot]  \n",
       "2573       [Corn, Gray leaf spot]  \n",
       "2574       [Corn, Gray leaf spot]  \n",
       "2575       [Corn, Gray leaf spot]  \n",
       "\n",
       "[2576 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3d56ce9-03ee-4682-b24f-ff9239a83a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = df['classes'].apply(pd.Series).stack().tolist()\n",
    "all_classes = set(all_classes)\n",
    "all_classes = np.array(list(all_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4ca3188-9442-4ada-a6aa-6f1e5492eb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6dbb6cf-b047-437b-84da-b74d99bc9166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tomato', 'leaf blight', 'Raspberry', 'Scab Leaf', 'grape',\n",
       "       'Soyabean', 'leaf black rot', 'Bell_pepper', 'mold leaf',\n",
       "       'Early blight leaf', 'Powdery mildew leaf', 'leaf bacterial spot',\n",
       "       'rust leaf', 'leaf early blight', 'Corn', 'Potato', 'Blueberry',\n",
       "       'Apple', 'leaf mosaic virus', 'leaf yellow virus', 'Squash',\n",
       "       'Strawberry', 'Septoria leaf spot', 'Gray leaf spot', 'Cherry',\n",
       "       'leaf spot', 'Peach', 'leaf late blight'], dtype='<U19')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "232d4265-26f7-452c-8da9-1a5d21b1b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = load_data(\n",
    "    train,\n",
    "    transform,\n",
    "    batch_size=50,\n",
    "    classes_list=all_classes\n",
    ")\n",
    "\n",
    "valid_loader = load_data(\n",
    "    valid,\n",
    "    transform,\n",
    "    batch_size=50,\n",
    "    classes_list=all_classes,\n",
    "    shuffle=False)\n",
    "\n",
    "# здесь classifier может меняться, зависит от предуобченной модели\n",
    "model.classifier = nn.Sequential(\n",
    "    # здесь число первое может меняться, зависит от предуобченной модели\n",
    "    nn.Linear(1280, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, all_classes.shape[0])\n",
    ")\n",
    "\n",
    "# Замораживаем все слои\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Размораживаем параметры последнего полносвязанного слоя (classifier)\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edb6c85e-d45b-4dcf-b65a-15e1f764bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/11 21:16:25 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:46<00:00,  1.12s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.14s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:47<00:00,  1.12s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.15s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:46<00:00,  1.12s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.15s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:46<00:00,  1.12s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.16s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:46<00:00,  1.12s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.15s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:47<00:00,  1.12s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.15s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:47<00:00,  1.13s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.15s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:47<00:00,  1.13s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.15s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:47<00:00,  1.13s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.16s/it]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:47<00:00,  1.13s/it]\n",
      "Validating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:12<00:00,  1.15s/it]\n",
      "2024/06/11 21:27:19 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/11 21:27:19 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.CrossEntropyLoss().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0, verbose=True)\n",
    "experiment_name = \"Plant_1\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.enable_system_metrics_logging()\n",
    "\n",
    "name_model = \"efficientnet_b0_10_PD_f1\"\n",
    "with mlflow.start_run(run_name=name_model) as run:\n",
    "    train_losses, train_accuracies, valid_accuracies, valid_accuracies = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        num_epochs,\n",
    "        name_model,\n",
    "        device=device,\n",
    "        scheduler=scheduler,\n",
    "        save=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0477cbb8-face-4ecd-b03c-fd014709e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goods_dataset = goodsDataset(df=df, \n",
    "                                transform=transform,\n",
    "                                classes_list=all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a6f22b4-c5bc-4b60-866e-b9e9fe980abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plantsdoc/corn-disease-update-fig-1-northern-leaf-blight.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"id\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcb471c-eba9-4009-9aec-f9be3a654fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goods_dataset[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e8070d9-0620-4fd1-9cfe-37cf6e7f90c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plantsdoc/corn-disease-update-fig-1-northern-leaf-blight.jpg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc4538-7768-4e20-ad2f-3bca7d27c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "goods_dataset.encode_label(self, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
